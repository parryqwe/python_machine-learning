{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot import plt\n",
    "import numpy as np\n",
    "def sigmoid(z):\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "z=np.arange(-7,7,0.1)\n",
    "phi_z=sigmoid(z)\n",
    "plt.plot(z,phi_z)\n",
    "plt.axvline(0.0,color='k')\n",
    "plt.axhspan(0.0,1.0,facecolor='1.0',alpha=1.0,ls='dotted')\n",
    "plt.axhline(y=0.5,ls='dotted',color='k')\n",
    "plt.yticks([0.0,0.5,1.0])\n",
    "plt.ylim(-0.1,1.1)\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('$\\phi (z)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression(C=1000.0,random_state=0)\n",
    "lr.fit(x_train_std,y_train)\n",
    "plot_decision_region(x_combined_std,y_combined,classifier=lr,test_idx=range(105,150))\n",
    "plt.xlabel('petal length [standardized]')\n",
    "plt.ylabel('petal width [standardized]')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict_proba(x_test_std[0,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights,params=[],[]\n",
    "for c in np.arange(-5,5):\n",
    "    lr=LogisticRegression(C=10**c,random_state=0)\n",
    "    lr.fit(x_train_std,y_train)\n",
    "    weights.append(lr.coef_[1])\n",
    "    params.append(10**c)\n",
    "weights=np.array(weights)\n",
    "plt.plot(params,weights[:,0],label='petal length')\n",
    "plt.plot(params,weights[:,1],linestyle='--',label='petal width')\n",
    "plt.ylabel('weight coefficient')\n",
    "plt.xlabel('C')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors=5,p=2,metric='minkowski')\n",
    "knn.fit(x_train_std,y_train)\n",
    "plot_decision_regions(x_combined_std,y_combined,classifier=knn,test_idx=range(105,150))\n",
    "plt.xlabel('petal l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[[0], [1], [2], [3]]\n",
    "y=[0, 0, 1, 1]\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "neigh = RadiusNeighborsClassifier(radius=1.0)\n",
    "neigh.fit(X, y)\n",
    "print(neigh.predict([[1.5]]))\n",
    "print(neigh.predict_proba([[1.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "samples = [[0, 0, 2], [1, 0, 0], [0, 0, 1]]\n",
    "neigh = NearestNeighbors(n_neighbors=2, radius=0.4)\n",
    "neigh.fit(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "x,y=make_blobs(100,2,centers=2,random_state=2,cluster_std=1.5)\n",
    "plt.scatter(x[:,0],x[:,1],c=y,s=50,cmap='RdBu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha, fit_prior, class_prior)\n",
    "clf.fit(X_train_tf, Y_train)\n",
    "predicted = clf.predict(X_pre_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = BernoulliNB()\n",
    "clf = clf.fit(iris.data, iris.target)\n",
    "y_pred=clf.predict(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "clf = ComplementNB()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model=GaussianNB()\n",
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng=np.random.RandomState(0)\n",
    "xnew=[-6,14]+[14,18]*rng.rand(2000,2)\n",
    "ynew=model.predict(xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x[:,0],x[:,1],c=y,s=50,cmap='RdBu')\n",
    "lim=plt.axis()\n",
    "plt.scatter(xnew[:,0],xnew[:,1],c=ynew,s=20,cmap='RdBu',alpha=0.1)\n",
    "plt.axis(lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yprob=model.predict_proba(xnew)\n",
    "yprob[-8:].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "data=fetch_20newsgroups()\n",
    "data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=['talk.religion.misc','soc.religion.christian','sci.space','comp.graphics']\n",
    "train=fetch_20newsgroups(subset='train',categories=categories)\n",
    "test=fetch_20newsgroups(subset='test',categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "model=make_pipeline(TfidfVectorizer(),MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train.data,train.target)\n",
    "labels=model.predict(test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "mat=confusion_matrix(test.target,labels)\n",
    "sns.heatmap(mat.T,square=True,annot=True,fmt='d',cbar=False,xticklabels=train.target_names,yticklabels=train.target_names)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_category(s,train=train,model=model):\n",
    "    pred=model.predict([s])\n",
    "    return train.target_names[pred[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator,ClassifierMixin\n",
    "class KDEClassifier(BaseEstimator,ClassifierMixin):\n",
    "    def __init__(self,bandwidth=1.0,kernel='gaussian'):\n",
    "        self.bandwidth=bandwidth\n",
    "        self.kernel=kernel\n",
    "    def fit(self,x,y):\n",
    "        self.classes_=np.sort(np.unique(y))\n",
    "        training_sets=[x[y==yi] for yi in self.classes_]\n",
    "        self.models_=[KernelDensity(bandwidth=self.bandwidth,kernel=self.kernel).fit(xi) for xi in training_sets]\n",
    "        self.logpriors_=[np.log(xi.shape[0]/x.shape[0]) for xi in training_sets]\n",
    "        return self\n",
    "    def predict_proba(self,x):\n",
    "        logprops=np.array([model.score_samples(x) for model in self.models_]).T\n",
    "        result=np.exp(logprops+self.logpriors_)\n",
    "        return result/result.sum(1,keepdims=True)\n",
    "    def predict(self,x):\n",
    "        return self.classes_[np.argmax(self.predict_proba(x),1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "digits=load_digits()\n",
    "bandwidths=10**np.linspace(0,2,100)\n",
    "grid=GridSearchCV(KDEClassifier(),{'bandwidth':bandwidth})\n",
    "grid.fit(digits.data,digits.target)\n",
    "scores=[val.mean_validation_score for val in grid.grid_scores_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(bandwidths,scores)\n",
    "plt.xlabel('bandwidth')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('KDE Model Performance')\n",
    "print(grid.best_params_)\n",
    "print('accuracy=',grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "x,y=make_blobs(n_samples=50,centers=2,random_state=0,cluster_std=0.6)\n",
    "plt.scatter(x[:,0],x[:,1],c=y,s=50,cmap='autumn')\n",
    "xfit=np.linspace(-1,3.5)\n",
    "plt.scatter(x[:,0],x[:,1],c=y,s=50,cmap='autumn')\n",
    "plt.plot([0.6],[2.1],'x',color='red',markeredgewidth=2,markersize=10)\n",
    "for m,b in [(1,0.65),(0.5,1.6),(-0.2,2.9)]:\n",
    "    plt.plot(xfit,m*xfit+b,'-k')\n",
    "plt.xlim(-1,3.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfit=np.linspace(-1,3.5)\n",
    "plt.scatter(x[:,0],x[:,1],c=y,s=50,cmap='autumn')\n",
    "for m,b,d in [(1,0.65,0.33),(0.5,1.6,0.55),(-0.2,2.9,0.2)]:\n",
    "    yfit=m*xfit+b\n",
    "    plt.plot(xfit,yfit,'-k')\n",
    "    plt.fill_between(xfit,yfit-d,yfit+d,edgecolor='none',color='#AAAAAA',alpha=0.4)\n",
    "plt.xlim(-1,3.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model=SVC(kernel='linear',C=1E10)\n",
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "model=LinearSVC(C=1E10)\n",
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import NuSVC\n",
    "model=NuSVC(kernel='linear',C=1E10)\n",
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_svc_decision_function(model,ax=None,plot_support=True):\n",
    "    if ax is None:\n",
    "        ax=plt.gca()\n",
    "    xlim=ax.get_xlim()\n",
    "    ylim=ax.get_ylim()\n",
    "    x=np.linspace(xlim[0],xlim[1],30)\n",
    "    y=np.linspace(ylim[0],ylim[1],30)\n",
    "    Y,X=np.meshgrid(y,x)\n",
    "    xy=np.vstack([X.ravel(),Y.ravel()]).T\n",
    "    P=model.decision_function(xy).reshape(X.shape)\n",
    "    ax.contour(X,Y,P,colors='k',levels=[-1,0,1],alpha=0.5,linestyles=['--','-','--'])\n",
    "    if plot_support:\n",
    "        ax.scatter(model.support_vectors_[:,0],model.support_vectors_[:,1],s=300,linewidth=1,facecolors='none')\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x[:,0],x[:,1],c=y,s=50,cmap='autumn')\n",
    "plot_svc_decision_function(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_svm(N=10,ax=None):\n",
    "    x,y=make_blobs(n_samples=200,centers=2,random_state=0,cluster_std=0.6)\n",
    "    x=x[:N]\n",
    "    y=y[:N]\n",
    "    model=SVC(kernel='linear',C=1E10)\n",
    "    model.fit(x,y)\n",
    "    ax=ax or plt.gca()\n",
    "    ax.scatter(x[:,0],x[:,1],c=y,s=50,cmap='autumn')\n",
    "    ax.set_xlim(-1,4)\n",
    "    ax.set_ylim(-1,6)\n",
    "    plot_svc_decision_function(model,ax)\n",
    "fig,ax=plt.subplots(1,2,figsize=(16,6))\n",
    "fig.subplots_adjust(left=0.0625,right=0.95,wspace=0.1)\n",
    "for axi,N in zip(ax,[60,120]):\n",
    "    plot_svm(N,axi)\n",
    "    axi.set_title('N={0}'.format(N))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_circles\n",
    "x,y=make_circles(100,factor=0.1,noise=0.1)\n",
    "clf=SVC(kernel='linear').fit(x,y)\n",
    "plt.scatter(x[:,0],x[:,1],c=y,s=50,cmap='autumn')\n",
    "plot_svc_decision_function(clf,plot_support=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=SVC(kernel='rbf',C=1E6)\n",
    "clf.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x[:,0],x[:,1],c=y,s=50,cmap='autumn')\n",
    "plot_svc_decision_function(clf)\n",
    "plt.scatter(clf.support_vectors_[:,0],clf.support_vectors_[:,1],s=300,lw=1,facecolors='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=make_blobs(n_samples=100,centers=2,random_state=0,cluster_std=1.2)\n",
    "plt.scatter(x[:,0],x[:,1],c=y,s=50,cmap='autumn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=make_blobs(n_samples=100,centers=2,random_state=0,cluster_std=0.8)\n",
    "fig,ax=plt.subplots(1,2,figsize=(16,6))\n",
    "fig.subplots_adjust(left=0.0625,right=0.95,wspace=0.1)\n",
    "for axi,C in zip(ax,[10.0,0.1]):\n",
    "    model=SVC(kernel='linear',C=C).fit(x,y)\n",
    "    axi.scatter(x[:,0],x[:,1],c=y,s=50,cmap='autumn')\n",
    "    plot_svc_decision_function(model,axi)\n",
    "    axi.scatter(model.support_vectors_[:,0],model.support_vectors_[:,1],s=300,lw=1,facecolors='none')\n",
    "    axi.set_title('C={0:0.1f}'.format(C),size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm=SVC(kernel='linear',C=1.0,random_state=0)\n",
    "svm.fit(x_train_std,y_train)\n",
    "plot_decision_regions(x_combined_std,y_combined,classifier=svm,test_idx=range(105,150))\n",
    "plt.xlabel('petal length [standardized]')\n",
    "plt.ylabel('petal width [standardized]')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "x_xor=np.random.randn(200,2)\n",
    "y_xor=np.logical_xor(x_xor[:,0]>0,x_xor[:,1]>0)\n",
    "y_xor=np.where(y_xor,1,-1)\n",
    "plt.scatter(x_xor[y_xor==1,0],x_xor[y_xor==1,1],c='b',marker='x',label='1')\n",
    "plt.scatter(x_xor[y_xor==-1,0],x_xor[y_xor==-1,1],c='r',marker='s',label='-1')\n",
    "plt.ylim(-3.0)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm=SVC(kernel='rbf',random_state=0,gamma=0.2,C=1.0)\n",
    "svm.fit(x_train_std,y_train)\n",
    "plot_decision_regions(x_combined_std,y_combined,classifier=svm,test_idx=range(105,150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm=SVC(kernel='rbf',random_state=0,gamma=100,C=1.0)\n",
    "svm.fit(x_train_std,y_train)\n",
    "plot_decision_regions(x_combined_std,y_combined,classifier=svm,test_idx=range(105,150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "x,y=make_blobs(n_samples=300,centers=4,random_state=0,cluster_std=1.0)\n",
    "plt.scatter(x[:,0],x[:,1],c=y,s=50,cmap='rainbow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree=DecisionTreeClassifier().fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_classifier(model,x,y,ax=None,cmap='rainbow'):\n",
    "    ax=ax or plt.gca()\n",
    "    ax.scatter(x[:,0],x[:,1],c=y,s=30,cmap=cmap,clim=(y.min(),y.max()),zorder=3)\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    xlim=ax.get_xlim()\n",
    "    ylim=ax.get_ylim()\n",
    "    model.fit(x,y)\n",
    "    xx,yy=np.meshgrid(np.linspace(*xlim,num=200),np.linspace(*ylim,num=200))\n",
    "    z=model.predict(np.c_[xx.ravel(),yy.ravel()]).reshape(xx.shape)\n",
    "    n_classes=len(np.unique(y))\n",
    "    contours=ax.contourf(xx,yy,z,alpha=0.3,levels=np.arange(n_classes+1)-0.5,cmap=cmap,clim=(y.min(),y.max()),zorder=1)\n",
    "    ax.set(xlim=xlim,ylim=ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_classifier(DecisionTreeClassifier(),x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def gini(p):\n",
    "    return (p)*(1-(p))+(1-p)*(1-(1-p))\n",
    "def entropy(p):\n",
    "    return -p*np.log2(p)-(1-p)*np.log2((1-p))\n",
    "def error(p):red\n",
    "    return 1-np.max([p,1-p])\n",
    "x=np.arange(0.0,1.0,0.01)\n",
    "ent=[entropy(p) if p!=0 else None for p in x]\n",
    "sc_ent=[e*0.5 if e else None for e in ent]\n",
    "err=[error(i) for i in x]\n",
    "fig=plt.figure()\n",
    "ax=plt.subplot(111)\n",
    "for i,lab,ls,c in zip([ent,sc_ent,gini(x),err],['Entropy','Entropy(scaled)','Gini Impurity','Misclassificatio Error'],['-','-','--','-.'],['black','lightgray','red','green','cyan']):\n",
    "    line=ax.plot(x,i,label=lab,linestyle=ls,lw=2,color=c)\n",
    "ax.legend(loc='upper center',bbox_to_anchor=(0.5,1.15),ncol=3,fancybox=True,shadow=False)\n",
    "ax.axhline(y=0.5,linewidth=1,color='k',linestyle='--')\n",
    "ax.axhline(y=1.0,linewidth=1,color='k',linestyle='--')\n",
    "plt.ylim([0,1.1])\n",
    "plt.xlabel('p(i=1)')\n",
    "plt.ylabel('Impurity Index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree=DecisionTreeClassifier(criterion='entropy',max_depth=3,random_state=0)\n",
    "tree.fit(x_train,y_train)\n",
    "x_combined=np.vstack([x_train,x_test])\n",
    "y_combined=np.hstack([y_train,y_test])\n",
    "plot_decision_regions(x_combined,y_combined,classifier=tree,test_idx=range(105,150))\n",
    "plt.xlabel('petal length(cm)')\n",
    "plt.ylabel('petal width(cm)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(tree,out_file='tree.dot',feature_names=['petal length','petal width'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree=DecisionTreeClassifier()\n",
    "bag=BaggingClassifier(tree,n_estimators=100,max_samples=0.8,random_state=1)\n",
    "bag.fit(x,y)\n",
    "visualize_classifier(bag,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model=RandomForestClassifier(n_estimators=100,random_state=0)\n",
    "visualize_classifier(model,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest=RandomForestClassifier(criterion='entropy',n_estimators=10,random_state=1,n_jobs=2)\n",
    "forest.fit(x_train,y_train)\n",
    "plot_decision_regions(x_combined,y_combined,classifier=forest,test_idx=range(105,150))\n",
    "plt.xlabel('petal length')\n",
    "plt.ylabel('petal width')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Perception(object):\n",
    "    def __init__(self,eta=0.01,n_iter=10):\n",
    "        self.eta=eta\n",
    "        self.n_iter=n_iter\n",
    "    def fit(self,x,y):\n",
    "        self.w_=np.zeros(1+x.shape[1])\n",
    "        self.errors_=[]\n",
    "        \n",
    "        for _ in range(self.n_iter):\n",
    "            errors=0\n",
    "            for xi,target in zip(x,y):\n",
    "                update=self.eta*(target-self.predict(x1))\n",
    "                self.w_[1:]+=update*xi\n",
    "                self.w_[0]+=update\n",
    "                errors+=int(update!=0.0)\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "    def net_input(self,x):\n",
    "        return np.dot(x,self.w_[1:])+self.w_[0]\n",
    "    def predict(self,x):\n",
    "        return np.where(self.net_input(x)>=0.0,1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot import plt\n",
    "import numpy as np\n",
    "y=df.iloc[0:100,4].values\n",
    "y=np.where(y=='Iris-setosa',-1,1)\n",
    "x=df.iloc[0:100,[0,2]].values\n",
    "plt.scatter(x[:49,0],x[:49,1],color='red',marker='o',label='setosa')\n",
    "plt.scatter(x[50:100,0],x[50:100,1],color='blue',marker='x',label='versicolor')\n",
    "plt.xlabel('petal length')\n",
    "plt.ylabel('sepal length')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppn=Perception(eta=0.1,n_iter=10)\n",
    "ppn.fit(x,y)\n",
    "plt.plot(range(1,len(ppn.errors_)+1),ppn.errors_,marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Number of misclassifications')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "def plot_decision_regions(x,y,classifier,resolution=0.02):\n",
    "    markers=('s','x','o','^','v')\n",
    "    colors=('red','blue','lightgreen','gray','cyan')\n",
    "    cmap=ListedColormap(colors[:len(np.unique(y))])\n",
    "    x1_min,x1_max=x[:,0].min()-1,x[:,0].max()+1\n",
    "    x2_min,x2_max=x[:,1].min()-1,x[:,1].max()+1\n",
    "    xx1,xx2=np.meshgrid(np.arange(x1_min,x1_max,resolution),np.arange(x2_min,x2_max,resolution))\n",
    "    z=classifier.predict(np.array([xx1.ravel(),xx2.ravel()]).T)\n",
    "    z=z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1,xx2,z,alpha=0.4,cmap=cmap)\n",
    "    plt.xlim(xx1.min(),xx1.max())\n",
    "    plt.ylim(xx2.min(),xx2.max())\n",
    "    for idx,cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=x[y==cl,0],y=x[y==cl,1],alpha=0.8,c=cmap(idx),marker=markers[idx],label=cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(x,y,classifier=ppn)\n",
    "plt.xlabel('sepal length [cm]')\n",
    "plt.ylabel('petal length [cm]')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import dataset\n",
    "import numpy as np\n",
    "iris=datasets.load_iris()\n",
    "x-iris.data[:,[2,3]]\n",
    "y=iris.target\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=0)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "sc.fit(x_train)\n",
    "x_train_std=sc.transform(x_train)\n",
    "x_test_std=sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "ppn=Perceptron(n_iter=40,eta0=0.1,random_state=0)\n",
    "ppn.fit(x_train_std,y_train)\n",
    "y_pred=ppd.predict(x_test_std)\n",
    "print('Misclassified samples:%d' % (y_test!=y_pred).sum())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy:%.2f' % accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_decision_regions(x,y,classifier,test_idx=None,resolution=0.02):\n",
    "    markers=('s','x','o','^','v')\n",
    "    colors=('red','blue','lightgreen','gray','cyan')\n",
    "    cmap=ListedColormap(colors[:len(np.unique(y))])\n",
    "    x1_min,x1_max=x[:,0].min()-1,x[:,0].max()+1\n",
    "    x2_min,x2_max=x[:,1].min()-1,x[:,1].max()+1\n",
    "    xx1,xx2=np.meshgrid(np.arange(x1_min,x1_max,resolution),np.arange(x2_min,x2_max,resolution))\n",
    "    z=classifier.predict(np.array([xx1.ravel(),xx2.ravel()]).T)\n",
    "    z=z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1,xx2,z,alpha=0.4,cmap=cmap)\n",
    "    plt.xlim(xx1.min(),xx1.max())\n",
    "    plt.ylim(xx2.min(),xx2.max())\n",
    "    x_test,y_test=x[test_idx,:],y[test_idx]\n",
    "    for idx,cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=x[y==cl,0],y=x[y==cl,1],alpha=0.8,c=cmap(idx),marker=markers[idx],label=cl)\n",
    "    if test_idx:\n",
    "        x_test,y_test=x[test_idx,:],y[test_idx]\n",
    "        plt.scatter(x_test[:,0],x_test[:,1],c=\"\",alpha=1.0,linewidth=1,marker='o',s=55,label='test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_combined_std=np.vstack((x_train_std,x_test_std))\n",
    "y_combined=np.hstack((y_train,y_test))\n",
    "plot_decision_regions(x=x_combined_std,y=y_combined,classifier=ppn,test_idx=range(105,150))\n",
    "plt.xlabel('petal length [standardized]')\n",
    "plt.ylabel('petal width [standardized]')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdalineGD(object):\n",
    "    def __init__(self,eta=0.01,n_iter=50):\n",
    "        self.eta=eta\n",
    "        self.n_iter=n_iter\n",
    "    def fit(self,x,y):\n",
    "        self.w_=np.zeros(1+x.shape[1])\n",
    "        self.cost_=[]\n",
    "        for i in range(self.n_iter):\n",
    "            output=self.net_input(x)\n",
    "            errors=(y-output)\n",
    "            self.w_[1:]+=self.eta*x.T.dot(errors)\n",
    "            self.w_[0]+=self.eta*errors.sum()\n",
    "            cost=(errors**2).sum()/2.0\n",
    "            self.cost_.append(cost)\n",
    "        return self\n",
    "    def net_input(self,x):\n",
    "        return np.dot(x,self.w_[1:]+self.w_[0])\n",
    "    def activation(self,x):\n",
    "        return self.net_input(x)\n",
    "    def predict(self,x):\n",
    "        return np.where(self.activation(x)>=0.0,1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(nrows=1,ncols=2,figsize=(8,4))\n",
    "ada1=AdalineGD(n_iter=10,eta=0.01).fit(x,y)\n",
    "ax[0].plot(range(1,len(ada1.cost_)+1),np.log10(ada1.cost_),marker='o')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('log(Sum-squared-error)')\n",
    "ax[0].set_title('Adaline-Learning rate 0.01')\n",
    "ada2=AdalineGD(n_iter=10,eta=0.0001).fit(x,y)\n",
    "ax[1].plot(range(1,len(ada2.cost_)+1),ada2.cost_,marker='o')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Sum-squared-error')\n",
    "ax[1].set_title('Adaline=Learning rate 0.0001')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada=AdalineGD(n_iter=15,eta=0.01)\n",
    "ada.fit(x_std,y)\n",
    "plot_decision_regions(x_std,y,classifier=ada)\n",
    "plt.title('Adaline-Gradient Descent')\n",
    "plt.xlabel('sepal length [standardized]')\n",
    "plt.ylabel('petal length [standardized]')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(range(1,len(ada.cost_)+1),ada.cost_,marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Sum-squared-error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "class AdalineSGD(object):\n",
    "    def __init__(self,eta=0.01,n_iter=10,shuffle=True,random_state=None):\n",
    "        self.eta=eta\n",
    "        self.n_iter=n_iter\n",
    "        self.w_initialized=False\n",
    "        self.shuffle=shuffle\n",
    "        if random_state:\n",
    "            seed(random_state)\n",
    "    def fit(self,x,y):\n",
    "        self._initialize_weights(x.shape[1])\n",
    "        self.cost_=[]\n",
    "        for i in range(self.n_iter):\n",
    "            if self.shuffle:\n",
    "                x,y=self._shuffle(x,y)\n",
    "            cost=[]\n",
    "            for xi,target in zip(x,y):\n",
    "                cost.append(self._update_weights(xi,target))\n",
    "            avg_cost=sum(cost)/len(y)\n",
    "            self.cost_.append(avg_cost)\n",
    "        return self\n",
    "    def partial_fit(self,x,y):\n",
    "        if not self.w_initialized:\n",
    "            self._initialize_weights(x.shape[1])\n",
    "        if y.ravel().shape[0]>1:\n",
    "            for xi,target in zip(x,y):\n",
    "                self._update_weights(xi,target)\n",
    "        else:\n",
    "            self._update_weights(x,y)\n",
    "        return self\n",
    "    def _shuffle(self,x,y):\n",
    "        r=np.random.permutation(len(y))\n",
    "        return x[r],y[r]\n",
    "    def _initialize_weights(self,m):\n",
    "        self.w_=np.zeros(1+m)\n",
    "        self.w_initialized=True\n",
    "    def _update_weights(self,xi,target):\n",
    "        output=self.net_input(xi)\n",
    "        error=(target-output)\n",
    "        self.w_[1:]+=self.eta*xi.dot(error)\n",
    "        self.w_[0]+=self.eta*error\n",
    "        cost=0.5*error**2\n",
    "        return cost\n",
    "    def net_input(self,x):\n",
    "        return np.dot(x,self.w_[1:])+self.w_[0]\n",
    "    def activation(self,x):\n",
    "        return self.net_input(x)\n",
    "    def predict(self,x):\n",
    "        return np.where(self.activation(x)>=0.0,1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada=AdalineSGD(n_iter=15,eta=0.01,random_state=1)\n",
    "ada.fit(x_std,y)\n",
    "plot_decision_regions(x_std,y,classifier=ada)\n",
    "plt.title('Adaline-Stochastic Gradient Descent')\n",
    "plt.xlabel('sepal length [standardized]')\n",
    "plt.ylabel('petal length [standardized]')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(range(1,len(ada.cost_)+1),ada.cost_,marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Average Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "ppn=SGDClassifier(loss=\"perceptron\")\n",
    "lr=SGDClassifier(loss=\"log\")\n",
    "svm=SGDClassifier(loss=\"hinge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.externals import six\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import _name_estimators\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MajorityVoteClassifier(BaseEstimator,ClassifierMixin):\n",
    "    def __init__(self,classifiers,vote='classlabel',weights=None):\n",
    "        self.classifiers=classifiers\n",
    "        self.named_classifiers={key:value for key,value in _name_estimators(classifiers)}\n",
    "        self.vote=vote\n",
    "        self.weights=weights\n",
    "    def fit(self,x,y):\n",
    "        self.lablenc_=LabelEncoder()\n",
    "        self.lablenc_.fit(y)\n",
    "        self.classes_=self.lablenc_.classes_\n",
    "        self.classifiers_=[]\n",
    "        for clf in self.classifiers:\n",
    "            fitted_clf=clone(clf).fit(x,self.lablenc_.transform(y))\n",
    "            self.classifiers_.append(fitted_clf)\n",
    "        return self\n",
    "    def predict(self,x):\n",
    "        if self.vote=='probability':\n",
    "            maj_vote=np.argmax(self.predict_proba(x),axis=1)\n",
    "        else:\n",
    "            predictions=np.asarray([clf.predict(x) for clf in self.classifiers_]).T\n",
    "        maj_vote=np.array_along_axis(lamda x:np.argmax(np.bincount(x,weight=self.weights)),axis=1,arr=predictions)\n",
    "        return maj_vote\n",
    "    def predict_proba(self,x):\n",
    "        probas=np.asarray([clf.predict_proba(x) for clf in self.classifiers_])\n",
    "        avg_proba=np.average(probas,axis=0,weights=self.weights)\n",
    "        return avg_proba\n",
    "    def get_params(self,deep=True):\n",
    "        if not deep:\n",
    "            return super(MajorityVoteClassifier,self).get_params(deep=False)\n",
    "        else:\n",
    "            out=self.named_classifiers.copy()\n",
    "            for name,step in six.iteritems(self.named_classifiers):\n",
    "                for key,value in six.iteritems(step.get_params(deep=True)):\n",
    "                    out['%s__%s' % (name,key)]=value\n",
    "            return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "clf1=LogisticRegression(penalty='l2',C=0.001,random_state=0)\n",
    "clf2=DecisionTreeClassifier(max_depth=1,critierion='entropy',random_state=0)\n",
    "clf3=KNeighborsClassifier(n_neighbors=1,p=2,metric='minkowski')\n",
    "pipe1=Pipeline([['sc',StandardScaler()],['clf',clf1]])\n",
    "pipe3=Pipeline([['sc',StandardScaler()],['clf',clf3]])\n",
    "clf_labels=['Logistic Regression','Decision Tree','KNN']\n",
    "print('10-fold cross validation:\\n')\n",
    "for clf,label in zip([pipe1,clf2,pipe3],clf_labels):\n",
    "    scores=cross_val_score(estimators=clf,x=x_train,y=y_train,cv=10,scoring='roc_auc')\n",
    "    print(\"ROC AUC:%0.2f (+/- %0.2f) [%s]\" % (scores.mean(),scores.std(),label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_clf=MajorityVoteClassifier(classifiers=[pipe1,clf2,pipe3])\n",
    "clf_labels+=['Majority Voting']\n",
    "all_clf=[pipe1,clf2,pipe3,mv_clf]\n",
    "for clf,label in zip(all_clf,clf_labels):\n",
    "    scores=cross_val_score(estimator=clf,x=x_train,y=y_train,cv=10,scoring='roc_auc')\n",
    "    print(\"Accuracy:%0.2f (+/-%0.2f) [%s]\" % (scores.mean(),scores.std(),label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "colors=['black','orange','blue','green']\n",
    "linestyle=[':','--','-.','-']\n",
    "for clf,label,clr,ls in zip(all_clf,clf_labels,colors,linestyles):\n",
    "    y_pred=clf.fit(x_train,y_train).predict_proba(x_test)[:,1]\n",
    "    fpr,tpr,thresholds=roc_curve(y_true=y_test,y_score=y_pred)\n",
    "    roc_auc=auc(x=fpr,y=tpr)\n",
    "    plt.plot(fpr,tpr,color=clr,linestyle=ls,label='%s (auc=%0.2f)' % (label,roc_auc))\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],linestyle='--',color='gray',linewidth=2)\n",
    "plt.xlim([-0.1,1.1])\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.grid()\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "params={'decisiontreeclassifier_max_depth':[1,2],'pipeline-1_clf_C':[0.001,0.1,100.0]}\n",
    "grid=GridSearchCV(estimator=mv_clf,param_grid=params,cv=10,scoring='roc_auc')\n",
    "grid.fit(x_train,y_train)\n",
    "for params,mean_score,scores in grid.grid_scores_:\n",
    "    print(\"%0.3f+/-%0.2f %r\" % (mean_score,scores_std() /2,params))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters:%s' % grid.best_params_)\n",
    "print('Accuracy:%.2f' % grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "tree=DecisionTreeClassifier(criterion='entropy',max_depth=None)\n",
    "bag=BaggingClassifier(base_estimator=tree,n_estimators=500,max_samples=1.0,max_features=1.0,bootstrap=True,bootstrap_features=False,n_jobs=1,random_state=1)\n",
    "from sklearn.metrics import accuracy_score\n",
    "tree=tree.fit(x_train,y_train)\n",
    "y_train_pred=tree.predict(x_train)\n",
    "y_test_pred=tree.predict(x_test)\n",
    "tree_train=accuracy_score(y_train,y_train_pred)\n",
    "tree_test=accuracy_score(y_test,y_test_pred)\n",
    "print('Decision tree train/test accuracies %.3f/%.3f' % (tree_train,tree_test))\n",
    "bag=bag.fit(x_train,y_train)\n",
    "y_train_pred=bag.predict(x_train)\n",
    "y_test_pred=bag.predict(x_test)\n",
    "bag_train=accuracy_score(y_train,y_train_pred)\n",
    "bag_test=accuracy_score(y_test,y_test_pred)\n",
    "print('Bagging train/test accuracies %.3f/%.3f' % (bag_train,bag_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "tree=DecisionTreeClassifier(criterion='entropy',max_depth=1)\n",
    "ada=AdaBoostClassifier(base_estimator=tree,n_estimators=500,learning_rate=0.1,random_state=0)\n",
    "tree=tree.fit(x_train,y_train)\n",
    "y_train_pred=tree.predict(x_train)\n",
    "y_test_pred=tree.predict(x_test)\n",
    "tree_train=accuracy_score(y_train,y_train_pred)\n",
    "tree_test=accuracy_score(y_test,y_test_pred)\n",
    "print('Decision tree train/test accuracies %.3f/%.3f' % (tree_train,tree_test))\n",
    "ada=ada.fit(x_train,y_train)\n",
    "y_train_pred=ada.predict(x_train)\n",
    "y_test_pred=ada.predict(x_test)\n",
    "ada_train=accuracy_score(y_train,y_train_pred)\n",
    "ada_test=accuracy_score(y_test,y_test_pred)\n",
    "print('Bagging train/test accuracies %.3f/%.3f' % (ada_train,ada_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = make_classification(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "clf = GradientBoostingClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.predict(X_test[:2])\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "linear = LinearRegression(normalize=False, fit_intercept=True, copy_X=True)\n",
    "gdbt = GradientBoostingRegressor(tol=0.1, subsample=0.37, n_estimators=200, max_features=20, \n",
    "                                 max_depth=6, learning_rate=0.03)\n",
    "rf = RandomForestRegressor(n_estimators=300, min_samples_split=9, min_samples_leaf=10, \n",
    "                           max_features='sqrt', max_depth=8, bootstrap=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
